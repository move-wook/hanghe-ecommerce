# 가상 장애 시나리오

## 모놀리식 아키텍처와 MSA 기반의 장애 대응을 비교해서 생각했다.

-  모놀리식 아키텍처와 MSA의 장애 대응 전략을 비교한다. 이를 통해 두 아키텍처의 차이점을 정리하고, 각 방식의 장단점을 분석하여 최적의 해결책을 모색한다.

## 장애 원인 및 영향 분석

## 문제 발생 원인

### 1. 트래픽 급증
특정 시간대에 주문 요청이 급격히 증가하면서 시스템의 부하가 급격히 상승하였다. 이에 따라 서버의 응답 시간이 지연되고, 일부 요청이 정상적으로 처리되지 못하는 문제가 발생하였다.

### 2. 서버 리소스 부족
과도한 트래픽으로 인해 CPU 및 메모리 사용량이 임계치를 초과하면서 성능 저하가 발생하였다. 이로 인해 응답 시간이 길어지고, 일정 임계점을 넘어서면서 **500 Internal Server Error**가 빈번하게 발생하였다.

### 3. 데이터베이스 부하 증가
비효율적인 쿼리 실행과 동시에 다량의 데이터 요청이 집중되면서 데이터베이스의 처리 속도가 저하되었다. 특히, 인덱스 미활용, 락 경합(lock contention), 트랜잭션 병목 등이 주요 원인으로 작용하였다.

### 4. 네트워크 병목 현상
대량의 주문 요청이 동시에 발생하면서 네트워크 대역폭이 포화 상태에 도달하였다. 이로 인해 요청과 응답 패킷의 전송 지연이 증가하고, 일부 요청이 타임아웃(timeout)되는 문제가 발생하였다.


# 장애 영향

본 장애는 단순히 주문 API 서버에 국한되지 않고, 데이터베이스 서버 및 네트워크에도 광범위한 영향을 미친다

- **응답 시간 증가**: 평균 응답 시간이 기존 **1초에서 5초 이상**으로 증가하여 사용자 경험이 저하됨.
- **오류 발생률 증가**: **500 Internal Server Error** 발생 비율이 **30% 이상**으로 증가하여 다수의 주문 요청이 정상적으로 처리되지 못함.
- **주문 처리 실패 및 상태 반영 오류**: 일부 사용자의 주문 요청이 실패하거나, 주문 상태가 정확하게 반영되지 않는 문제가 발생함.

이러한 장애로 인해 전체 시스템의 안정성이 저하되었으며, 원활한 주문 처리를 위한 장애 대응 전략이 필요함을 시사한다. 

# 3. 장애 대응 비교: 모놀리식 아키텍처 vs MSA

## 3.1 장애 대응 전략 
본 연구에서는 장애 발생 시의 대응 방안을 **모놀리식 아키텍처**와 **마이크로서비스 아키텍처(MSA)**로 구분하여 비교한다.

### (1) 모놀리식 아키텍처에서의 장애 대응

모놀리식 아키텍처는 단일 코드베이스로 구성되며, 모든 기능이 하나의 프로세스 내에서 실행된다. 이로 인해 장애 발생 시 다음과 같은 대응이 필요하다.

#### - **서버 모니터링 및 트래픽 분석**
- 전체 서버 리소스(CPU, 메모리, 네트워크)를 실시간으로 모니터링하여 병목을 분석한다.
- 트래픽 분포를 분석하고 부하가 집중되는 시간대를 식별한다.

#### - **리소스 확장**
- 단일 애플리케이션 구조이므로 서버 자체를 **수직 확장(Scale-Up)** 하는 방법이 일반적이다.
- **로드 밸런서**를 활용하여 여러 인스턴스에 트래픽을 분산할 수 있다.

#### - **쿼리 최적화 및 캐싱 적용**
- 데이터베이스의 **인덱스를 최적화**하여 쿼리 성능을 향상한다.
- Redis 등의 **캐시 시스템을 적용**하여 반복적인 데이터 요청을 줄인다.

#### - **서버 재시작 및 장애 복구**
- 서버를 재시작하여 불필요한 리소스를 정리하고, 시스템을 안정적인 상태로 복구한다.
- 장애 발생 시 **전체 시스템을 재배포**해야 하므로 복구 시간이 상대적으로 길다.

---

### (2) MSA에서의 장애 대응

마이크로서비스 아키텍처(MSA)는 기능별로 독립적인 서비스로 구성되므로, 특정 서비스에서 장애가 발생하더라도 **다른 서비스에 미치는 영향을 최소화할 수 있다**. MSA 기반의 장애 대응 방안은 다음과 같다.

#### - **서비스별 모니터링 및 트래픽 분석**
- 개별 **마이크로서비스의 CPU 및 메모리 사용량을 모니터링**하여 특정 서비스에서 발생한 병목을 분석한다.
- 특정 서비스에서만 부하가 집중되었는지 확인하고, 서비스 간의 트래픽 흐름을 점검한다.

#### - **개별 서비스 확장**
- 주문 API 서비스만 **수평 확장(Scale-Out)** 하여 필요한 리소스만 증가시킬 수 있다.
- **컨테이너 오케스트레이션(Kubernetes 등)을 활용한 자동 확장(Auto Scaling)** 을 적용한다.

#### - **데이터베이스 분산 및 캐싱**
- 주문 서비스에 최적화된 **별도의 데이터베이스를 구성**하여 부하를 분산한다.
- 서비스별 **Redis 캐시를 적용**하여 데이터베이스 조회를 최소화한다.

#### - **장애 발생 서비스만 복구**
- 특정 서비스에서 장애가 발생하더라도 **전체 시스템을 중단하지 않고**, 해당 서비스만 롤백 또는 재배포할 수 있다.
- **주문 API 서비스만 롤링 업데이트(Rolling Update)** 방식으로 배포하면 장애 복구 시간을 단축할 수 있다.

이러한 차이점을 바탕으로, 아키텍처별 장애 대응 방식의 장단점을 분석하여 최적의 전략을 도출할 수 있다.